{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a571e804",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "205474f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "dog_dir = \"train/DOGS/\"\n",
    "cat_dir = \"train/CATS/\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eed7f2de",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_width, image_height =224, 224"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bfbe87fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and preprocess the dog images\n",
    "dog_images = []\n",
    "for filename in os.listdir(dog_dir):\n",
    "    img = cv2.imread(os.path.join(dog_dir, filename))\n",
    "    img = cv2.resize(img, (image_width, image_height))\n",
    "    img = img.astype('float32') / 255.0\n",
    "    dog_images.append(img)\n",
    "dog_images = np.array(dog_images)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7907cf87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and preprocess the cat images\n",
    "cat_images = []\n",
    "for filename in os.listdir(cat_dir):\n",
    "    img = cv2.imread(os.path.join(cat_dir, filename))\n",
    "    img = cv2.resize(img, (image_width, image_height))\n",
    "    img = img.astype('float32') / 255.0\n",
    "    cat_images.append(img)\n",
    "cat_images = np.array(cat_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9b343943",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "2/2 [==============================] - 11s 2s/step - loss: 0.8854 - accuracy: 0.4524\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 7s 2s/step - loss: 0.8183 - accuracy: 0.6905\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 7s 2s/step - loss: 0.5938 - accuracy: 0.7381\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 6s 2s/step - loss: 0.7745 - accuracy: 0.6905\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 6s 2s/step - loss: 0.5827 - accuracy: 0.6905\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 6s 2s/step - loss: 0.5082 - accuracy: 0.6905\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 7s 2s/step - loss: 0.5538 - accuracy: 0.6905\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 8s 2s/step - loss: 0.4582 - accuracy: 0.7381\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 8s 2s/step - loss: 0.3948 - accuracy: 0.7619\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 8s 2s/step - loss: 0.4233 - accuracy: 0.7143\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 9s 3s/step - loss: 0.3770 - accuracy: 0.9524\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 13s 3s/step - loss: 0.3487 - accuracy: 0.9524\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 9s 2s/step - loss: 0.3498 - accuracy: 0.7619\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 7s 2s/step - loss: 0.2753 - accuracy: 0.8571\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 7s 2s/step - loss: 0.2918 - accuracy: 0.9762\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 7s 2s/step - loss: 0.2597 - accuracy: 1.0000\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 7s 2s/step - loss: 0.2019 - accuracy: 0.9524\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 7s 2s/step - loss: 0.1676 - accuracy: 0.9762\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 7s 2s/step - loss: 0.0833 - accuracy: 1.0000\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 7s 2s/step - loss: 0.0476 - accuracy: 1.0000\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.2116 - accuracy: 0.9091\n",
      "Test loss: 0.2116159051656723\n",
      "Test accuracy: 0.9090909361839294\n",
      "1/1 [==============================] - 0s 421ms/step\n",
      "The given image is not a dog.\n"
     ]
    }
   ],
   "source": [
    "# Create the labels for dog and cat images (1 for dog, 0 for cat)\n",
    "dog_labels = np.ones(len(dog_images))\n",
    "cat_labels = np.zeros(len(cat_images))\n",
    "\n",
    "# Concatenate the dog and cat data\n",
    "data = np.concatenate((dog_images, cat_images), axis=0)\n",
    "labels = np.concatenate((dog_labels, cat_labels), axis=0)\n",
    "\n",
    "# Shuffle the data and labels\n",
    "indices = np.random.permutation(len(data))\n",
    "data = data[indices]\n",
    "labels = labels[indices]\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "train_split = 0.8  # 80% for training, 20% for testing\n",
    "split_idx = int(train_split * len(data))\n",
    "\n",
    "train_data = data[:split_idx]\n",
    "train_labels = labels[:split_idx]\n",
    "test_data = data[split_idx:]\n",
    "test_labels = labels[split_idx:]\n",
    "\n",
    "# Define the model architecture\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(image_width, image_height, 3)))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(train_data, train_labels, epochs=20, batch_size=32)\n",
    "\n",
    "# Evaluate the model on the test dataset\n",
    "loss, accuracy = model.evaluate(test_data, test_labels)\n",
    "print(f\"Test loss: {loss}\")\n",
    "print(f\"Test accuracy: {accuracy}\")\n",
    "\n",
    "# Load and preprocess a new image for prediction\n",
    "new_image_path = \"test\\\\DOGS\\\\dog3.jpg\"\n",
    "new_image = cv2.imread(new_image_path)\n",
    "new_image = cv2.resize(new_image, (image_width, image_height))\n",
    "new_image = new_image.astype('float32') / 255.0\n",
    "new_image = np.expand_dims(new_image, axis=0)\n",
    "\n",
    "# Predict the class of the new image\n",
    "prediction = model.predict(new_image)\n",
    "is_dog = prediction[0][0] > 0.5\n",
    "\n",
    "if is_dog:\n",
    "    print(\"The given image is a dog.\")\n",
    "else:\n",
    "    print(\"The given image is not a dog.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "848ce749",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b59ac4b4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
